# Redis SRE Agent Configuration

# Application
DEBUG=false
LOG_LEVEL=INFO
HOST=0.0.0.0
PORT=8080

REDIS_SRE_MASTER_KEY=your_generated_key

# Redis
REDIS_URL=redis://localhost:7843/0
# REDIS_PASSWORD=your_redis_password

# =============================================================================
# LLM Configuration
# =============================================================================
# When using Docker Compose, the agent connects through LiteLLM proxy.
# Token flow:
#   1. OPENAI_API_KEY (real key) -> goes to LiteLLM container only
#   2. LITELLM_MASTER_KEY -> used by sre-agent/sre-worker to auth with LiteLLM
#   3. Docker Compose sets OPENAI_API_KEY=$LITELLM_MASTER_KEY for agent/worker
#
# For local development WITHOUT Docker/LiteLLM, set OPENAI_API_KEY directly.
# =============================================================================

# Real OpenAI API key - used by LiteLLM to call OpenAI
OPENAI_API_KEY=sk-your-real-openai-key

# LiteLLM master key - clients authenticate to proxy with this
LITELLM_MASTER_KEY=sk-1234

# Optional: Anthropic API key for Claude models via LiteLLM
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-key

# LiteLLM UI credentials
LITELLM_UI_USERNAME=admin
LITELLM_UI_PASSWORD=admin

# Model selection
OPENAI_MODEL=gpt-4
OPENAI_MODEL_MINI=gpt-4o-mini
OPENAI_MODEL_NANO=gpt-4o-mini

# =============================================================================
# Embeddings Configuration
# =============================================================================
# Provider: 'openai' (default) or 'local' (air-gap compatible)
EMBEDDING_PROVIDER=openai

# For OpenAI provider:
EMBEDDING_MODEL=text-embedding-3-small
VECTOR_DIM=1536

# For local provider (HuggingFace sentence-transformers, no API needed):
# EMBEDDING_PROVIDER=local
# EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# VECTOR_DIM=384
#
# Alternative local model (better quality, larger):
# EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2
# VECTOR_DIM=768

# Task Queue
TASK_QUEUE_NAME=sre_agent_tasks
MAX_TASK_RETRIES=3
TASK_TIMEOUT=300

# Agent Configuration
MAX_ITERATIONS=25
TOOL_TIMEOUT=60

# Monitoring Integration (Optional)
# PROMETHEUS_URL=http://prometheus:9090
# GRAFANA_URL=http://grafana:3000
# GRAFANA_API_KEY=your_grafana_api_key


# Tool Providers (Optional)
# TOOLS_PROMETHEUS_URL=http://localhost:9090
# TOOLS_LOKI_URL=http://localhost:3100

# Security (Optional)
# API_KEY=your_api_authentication_key
ALLOWED_HOSTS=["*"]

# Observability (Optional)
# OpenTelemetry tracing (opt-in)
# OTEL_EXPORTER_OTLP_ENDPOINT=http://your-collector:4318/v1/traces
# OTEL_EXPORTER_OTLP_HEADERS=Authorization=Bearer your-token

# LangSmith tracing for LangGraph workflows (opt-in)
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_API_KEY=your-langsmith-api-key
# LANGCHAIN_PROJECT=redis-sre-agent
